{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nb\n",
    "import nipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nipy.algorithms.registration\n",
    "from ip_utils2 import *\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from glob import glob\n",
    "from subprocess import call\n",
    "\n",
    "def warp_mni_to_img(target, warp, phy_coords):\n",
    "    ''' Warp (physical-space) MNI-space coords to a target image. '''\n",
    "    phy_coords = np.array([[-24.,-1.,-21.]]).T\n",
    "    warp = nb.load(os.path.join('/hcp/115320/MNINonLinear/xfms/standard2acpc_dc.nii.gz'))\n",
    "    target = nb.load(os.path.join('/data/hcp/data/115320/dwi_MD.nii.gz'))\n",
    "    warp_img_coords = xform_coords(np.linalg.inv(warp.get_affine()), phy_coords)\n",
    "    warp_data = warp.get_data()\n",
    "    xo = ndimage.map_coordinates(warp_data[...,0], warp_img_coords, order=1)\n",
    "    yo = ndimage.map_coordinates(warp_data[...,1], warp_img_coords, order=1)\n",
    "    zo = ndimage.map_coordinates(warp_data[...,2], warp_img_coords, order=1)\n",
    "    phy_coords[0,:] -= xo\n",
    "    phy_coords[1,:] += yo\n",
    "    phy_coords[2,:] += zo\n",
    "    warped_img_coords = xform_coords(np.linalg.inv(target.get_affine()), phy_coords)\n",
    "    return warped_img_coords\n",
    "\n",
    "def warp_img_to_mni(source, warp, img_coords, mni_ref=None):\n",
    "    ''' Warp source image coords to mni space. If an mni reference image is passed, \n",
    "        then the coordinates returned are in that image space. If mni_ref is none,\n",
    "        the returned coords are in MNI physical space.\n",
    "    '''\n",
    "    phy_coords = xform_coords(source.get_affine(), img_coords)\n",
    "    warp_img_coords = xform_coords(np.linalg.inv(warp.get_affine()), phy_coords)\n",
    "    warp_data = warp.get_data()\n",
    "    xo = ndimage.map_coordinates(warp_data[...,0], warp_img_coords, order=1)\n",
    "    yo = ndimage.map_coordinates(warp_data[...,1], warp_img_coords, order=1)\n",
    "    zo = ndimage.map_coordinates(warp_data[...,2], warp_img_coords, order=1)\n",
    "    phy_coords[0,:] -= xo\n",
    "    phy_coords[1,:] += yo\n",
    "    phy_coords[2,:] += zo\n",
    "    if mni_ref==None:\n",
    "        return phy_coords\n",
    "    else:\n",
    "        return xform_coords(np.linalg.inv(mni_ref.get_affine()), phy_coords)\n",
    "\n",
    "def xform_sl(subcode, sl_file, img_coords=True):\n",
    "    out_dir = os.path.join('/data/hcp/data',subcode)\n",
    "    warp = nb.load(os.path.join('/hcp',subcode,'MNINonLinear/xfms/acpc_dc2standard.nii.gz'))\n",
    "    mni = nb.load('/usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz')\n",
    "    #fa = nb.load(os.path.join(out_dir,'dwi_FA.nii.gz'))\n",
    "    ref = nb.load(os.path.join('/hcp', subcode, 'T1w/T1w_acpc_dc_restore_1.25.nii.gz'))\n",
    "    sl = load_streamline_file(os.path.join(out_dir, sl_file))\n",
    "    if img_coords:\n",
    "        slx = [warp_img_to_mni(ref, warp, np.array(s).T, mni).T.tolist() for s in sl]\n",
    "    else:\n",
    "        slx = [warp_img_to_mni(ref, warp, np.array(s).T).T.tolist() for s in sl]\n",
    "    return(slx)\n",
    "    \n",
    "def make_roi(target, warp, mni_roi, dilation=0):\n",
    "    sz = target.shape\n",
    "    # Image space coords of target:\n",
    "    #x,y,z = np.meshgrid(range(sz[0]),range(sz[1]),range(sz[2]), indexing='ij')\n",
    "    img_coords = np.array(np.meshgrid(range(sz[0]),range(sz[1]),range(sz[2]), indexing='ij')).reshape((3,-1))\n",
    "    # Physical space coords of target:\n",
    "    phy_coords = xform_coords(target.get_affine(), img_coords)\n",
    "    # MNI image space coords for target \n",
    "    mni_img_coords = xform_coords(np.linalg.inv(warp.get_affine()), phy_coords)\n",
    "    # pull the offsets from the MNI-space LUT\n",
    "    warp_data = warp.get_data()\n",
    "    xo = ndimage.map_coordinates(warp_data[...,0], mni_img_coords, order=1)\n",
    "    yo = ndimage.map_coordinates(warp_data[...,1], mni_img_coords, order=1)\n",
    "    zo = ndimage.map_coordinates(warp_data[...,2], mni_img_coords, order=1)\n",
    "    # Apply the offsets to physical space coords of the target\n",
    "    # FIXME: I think the +/- is related to the affine. These values work for the images \n",
    "    # that we are processing (i.e., our results match fsl's applywarp). But I suspect\n",
    "    # this is not a general solution...\n",
    "    phy_coords[0,:] -= xo\n",
    "    phy_coords[1,:] += yo\n",
    "    phy_coords[2,:] += zo\n",
    "    # convert the target physical space coords to roi image space\n",
    "    roi_coords = xform_coords(np.linalg.inv(mni_roi.get_affine()), phy_coords)\n",
    "    # Pull the values from the ROI map\n",
    "    roi_vals = ndimage.map_coordinates(mni_roi.get_data(), roi_coords, order=1)\n",
    "    roi_vals = roi_vals.reshape(sz)\n",
    "    if dilation>0:\n",
    "        roi_vals = ndimage.binary_dilation(roi_vals, iterations=dilation)\n",
    "    roi_vals = ndimage.binary_fill_holes(roi_vals).astype(np.int8)\n",
    "    roi = nb.Nifti1Image(roi_vals, target.get_affine())\n",
    "    return roi\n",
    "\n",
    "def make_rois(subcode, roi_names, roi_dilation=None, qa=False):\n",
    "    out_dir = os.path.join('/data/hcp/data',subcode)\n",
    "    sub_dir = os.path.join('/hcp',subcode)\n",
    "    mni_lut = nb.load(os.path.join(sub_dir,'MNINonLinear/xfms/standard2acpc_dc.nii.gz'))\n",
    "    #t1 = nb.load(os.path.join(sub_dir,'T1w/T1w_acpc_dc.nii.gz')\n",
    "    #ref = nb.load(os.path.join(out_dir,'dwi_FA.nii.gz'))\n",
    "    ref = nb.load(os.path.join(sub_dir,'T1w', 'Diffusion', 'nodif_brain_mask.nii.gz'))\n",
    "    for i,roi_name in enumerate(roi_names):\n",
    "        mni_roi = nb.load('/data/ROIs/' + roi_name + '.nii.gz')\n",
    "        if roi_dilation!=None and len(roi_dilation)>i:\n",
    "            dilation = roi_dilation[i]\n",
    "            print('Dilating %s by %d...' % (roi_name, dilation))\n",
    "        roi = make_roi(ref, mni_lut, mni_roi, roi_dilation)\n",
    "        nb.save(roi, os.path.join(out_dir, 'ROI_'+roi_name+'.nii.gz'))\n",
    "        if qa:\n",
    "            sl = xform_coord(roi.get_affine(), np.array(np.where(roi.get_data())).mean(axis=1)).round()\n",
    "            outfile = os.path.join(out_dir, subcode+'_ROI_'+roi_name+'.png')\n",
    "            show_brain(fa, sl=sl, overlay_file=roi, overlay_clip=[1,2], outfile=outfile)\n",
    "        \n",
    "def make_rois_fsl(subcode, roi_names, roi_dir='/data/ROIs/'):\n",
    "    out_dir = os.path.join('/data/hcp/data',subcode)\n",
    "    warp = os.path.join('/hcp',subcode,'MNINonLinear/xfms/standard2acpc_dc.nii.gz')\n",
    "    ref = os.path.join('/hcp',subcode,'T1w', 'Diffusion', 'nodif_brain_mask.nii.gz')\n",
    "    for i,roi_name in enumerate(roi_names):\n",
    "        infile = os.path.join(roi_dir,roi_name)\n",
    "        outfile = os.path.join(out_dir, 'ROI_'+roi_name+'_fsl.nii.gz')\n",
    "        call(['applywarp', '-i', infile, '-r', ref, '-w', warp, '-o', outfile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test warping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img_in: [[  28.  122.   69.]], MNI: [[ 60.  28.  14.]], Img_out: [[  28.  122.   69.]]\n",
      "Img_in: [[  32.  132.   62.]], MNI: [[ 48.  39.   7.]]\n"
     ]
    }
   ],
   "source": [
    "img_coords_orig = np.array([[28.,122.,69.]],dtype=np.float32)\n",
    "#img_coords_orig = sl[0][-1:,:]\n",
    "\n",
    "subcode = '100408'\n",
    "warp_to_img = nb.load(os.path.join('/hcp',subcode,'MNINonLinear/xfms/acpc_dc2standard.nii.gz'))\n",
    "warp_to_mni = nb.load(os.path.join('/hcp',subcode,'MNINonLinear/xfms/standard2acpc_dc.nii.gz'))\n",
    "mni = nb.load('/usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz')\n",
    "ref = nb.load(os.path.join('/hcp', subcode, 'T1w/T1w_acpc_dc_restore_1.25.nii.gz'))\n",
    "\n",
    "mni_coords = warp_img_to_mni(ref, warp_to_mni, img_coords_orig.T).T\n",
    "img_coords = warp_mni_to_img(ref, warp_to_img, mni_coords.copy().T).T\n",
    "print('Img_in: '+str(img_coords_orig.round())+', MNI: '+str(mni_coords.round())+', Img_out: '+str(img_coords.round()))\n",
    "\n",
    "sl_file = os.path.join('/data/hcp/data/',subcode,'RVLPFC2FIRSTamyg_bigRight_optimized.trk')\n",
    "sl_trk,hdr = nb.trackvis.read(sl_file, points_space='voxel')\n",
    "sl = [s[0] for s in sl_trk]\n",
    "\n",
    "sl_mni_coords = warp_img_to_mni(ref, warp_to_img, sl[0].T).T\n",
    "print('Img_in: '+str(sl[0][-1:,:].round())+', MNI: '+str(sl_mni_coords[-1:,:].round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  30.,  114.,   65.]], dtype=float32), array([[ 49.,  20.,   4.]]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sl[0][-1:,:].round(),sl_mni_coords[-1:,:].round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  29.66108475],\n",
       "       [ 114.17694321],\n",
       "       [  64.82564278]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xform_coords(np.linalg.inv(ref.get_affine()), mni_coords.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mni_to_img(target, warp, phy_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merge MNI-space track files to summarize group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.segment import select\n",
    "from dipy_run import *\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "from dipy.segment.metric import ResampleFeature\n",
    "from dipy.segment.metric import AveragePointwiseEuclideanMetric\n",
    "feature = ResampleFeature(nb_points=50)\n",
    "metric = AveragePointwiseEuclideanMetric(feature)\n",
    "qb = QuickBundles(threshold=15., metric=metric)\n",
    "\n",
    "def save_to_trackvis(streamlines, outname, dims, pixdim):\n",
    "    hdr = nb.trackvis.empty_header()\n",
    "    hdr['voxel_size'] = pixdim\n",
    "    hdr['voxel_order'] = 'LAS'\n",
    "    hdr['dim'] = dims\n",
    "    trk = ((sl, None, None) for sl in streamlines)\n",
    "    nb.trackvis.write(outname, trk, hdr, points_space='voxel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trk_file = 'amyg_rifg12.trk'\n",
    "#trk_file = 'amyg_rm1.trk'\n",
    "#trk_file = 'amyg_rsfg.trk'\n",
    "subcodes = sorted([os.path.basename(d) for d in glob('/data/hcp/data/*') \n",
    "                   if os.path.exists(os.path.join(d,trk_file))])\n",
    "len(subcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Get the centroid of the largest cluster for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fibers for each subject, transforming to MNI space \n",
    "slx = []\n",
    "for sc in subcodes:\n",
    "    slx.append(xform_sl(sc, trk_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster each subject's fibers\n",
    "clusters = []\n",
    "for sl in slx:\n",
    "    clusters.append(qb.cluster([np.array(s) for s in sl]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the largest cluster for each subject\n",
    "slx_all = []\n",
    "for c in clusters:\n",
    "    if len(c)>0:\n",
    "        clust_num = np.array(map(len,c)).argmax()\n",
    "        slx_all.append(c.centroids[clust_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the centroid of the largest cluster for each subject\n",
    "ni = nb.load('/usr/share/fsl/data/standard/MNI152_T1_1mm.nii.gz')\n",
    "dims = ni.shape\n",
    "pixdim = ni.header.get_zooms()\n",
    "save_to_trackvis(slx_all, '/data/hcp/mni_all_centroids_'+trk_file, dims, pixdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trk_file = '2M_SIFT.trk'\n",
    "roi_names = ['RVLPFC_12mm_54_27_12','FIRSTamyg_smRight']\n",
    "#roi_names = ['RVLPFC_15mm_54_27_12','FIRSTamyg_bigRight']\n",
    "#roi_names = ['RSFG_10mm_gm','RM1_gm']\n",
    "subcodes = sorted([os.path.basename(d) for d in glob('/data/hcp/data/*') \n",
    "                   if os.path.exists(os.path.join(d,trk_file)) \n",
    "                   #and os.path.exists(os.path.join(d,'dwi_MD.nii.gz'))\n",
    "                   and not os.path.exists(os.path.join(d,'ROI_'+roi_names[0]+'.nii.gz'))])\n",
    "len(subcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subcode in subcodes:\n",
    "    #if not os.path.exists(os.path.join('/data/hcp/data',subcode,'ROI_FIRSTamyg_bigRight_fsl.nii.gz')):\n",
    "    #make_rois_fsl(subcode, roi_names)\n",
    "    if not os.path.exists(os.path.join('/data/hcp/data',subcode,'ROI_'+roi_names[0]+'.nii.gz')):\n",
    "        print('making ROIs for ' + subcode + '...')\n",
    "        make_rois(subcode, roi_names)\n",
    "    else:\n",
    "        print('skipping ' + subcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test mni warping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp_mni_to_img\n",
    "phy_coords = np.array([[-24.,-1.,-21.],[54.,33.,10.]]).T\n",
    "warp = nb.load(os.path.join('/hcp/115320/MNINonLinear/xfms/standard2acpc_dc.nii.gz'))\n",
    "target = nb.load(os.path.join('/data/hcp/data/115320/dwi_MD.nii.gz'))\n",
    "\n",
    "warped_img_coords = warp_mni_to_img(target, warp, phy_coords)\n",
    "warped_img_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source =  nb.load(os.path.join('/data/hcp/data/115320/dwi_MD.nii.gz'))\n",
    "warp = nb.load(os.path.join('/hcp/115320/MNINonLinear/xfms/acpc_dc2standard.nii.gz'))\n",
    "\n",
    "warp_img_to_mni(source, warp, warped_img_coords, mni_ref=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Quality Check\n",
    "Display the normalized ROIs from the TMS stimulation study on the HCP data for visual inspection of ROI alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = nb.load('/data/hcp/data/100307/ROI_FIRSTamyg_smRight.nii.gz')\n",
    "t1 = nb.load('/hcp/100307/T1w/T1w_acpc_dc_restore_1.25.nii.gz')\n",
    "sl = xform_coord(roi.get_affine(), np.array(np.where(roi.get_data())).mean(axis=1)).round()\n",
    "show_brain(t1, sl=sl, overlay_file=roi, clip=99, overlay_clip=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trk_file = '2M_SIFT.trk'\n",
    "subcodes = sorted([os.path.basename(d) for d in glob('/data/hcp/data/*') \n",
    "                   if os.path.exists(os.path.join(d,trk_file))\n",
    "                   and os.path.exists(os.path.join(d,'ROI_FIRSTamyg_bigRight.nii.gz'))])\n",
    "len(subcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_names = ['RVLPFC_15mm_54_27_12','FIRSTamyg_bigRight','RVLPFC_15mm_54_27_12_fsl','FIRSTamyg_bigRight_fsl']\n",
    "outdir = '/data/hcp/data/'\n",
    "for sc in subcodes:\n",
    "    #md = nb.load(os.path.join(outdir, sc, 'dwi_MD.nii.gz'))\n",
    "    md = nb.load(os.path.join('/hcp', sc, 'T1w/T1w_acpc_dc_restore_1.25.nii.gz'))\n",
    "    for roi_name in roi_names:\n",
    "        roi = nb.load(os.path.join(outdir, sc, 'ROI_' + roi_name + '.nii.gz'))\n",
    "        sl = xform_coord(roi.get_affine(), np.array(np.where(roi.get_data())).mean(axis=1)).round()\n",
    "        outfile = os.path.join(out_dir, sc+'_ROI_'+roi_name+'.png')\n",
    "        show_brain(md, sl=sl, overlay_file=roi, clip=99, overlay_clip=[1,2], outfile=outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
